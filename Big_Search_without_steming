{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"FuPZF650yYQR"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import sys\n","from collections import Counter, OrderedDict\n","import itertools\n","from itertools import islice, count, groupby\n","import pandas as pd\n","import os\n","import re\n","from operator import itemgetter\n","import nltk\n","from nltk.stem.porter import *\n","from nltk.corpus import stopwords\n","from time import time\n","from timeit import timeit\n","from pathlib import Path\n","import pickle\n","import pandas as pd\n","import numpy as np\n","import math\n","from operator import add\n","import builtins\n","from google.cloud import storage\n","from collections import defaultdict\n","\n","import hashlib\n","def _hash(s):\n","    return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n","\n","nltk.download('stopwords')\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"7Nr6-dSuydBv"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n","\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n"]}],"source":["!pip install -q google-cloud-storage==1.43.0\n","!pip install -q graphframes"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"fSaGnJwWyfb8"},"outputs":[],"source":["import pyspark\n","from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf, SparkFiles\n","from pyspark.sql import SQLContext\n","from pyspark.ml.feature import Tokenizer, RegexTokenizer\n","from graphframes import *"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"h1GP_NHzyicB"},"outputs":[],"source":["def open_gcp(file_name,dir_name):\n","    client = storage.Client(file_name)\n","    bucket = client.bucket(bucket_name)\n","    blob = bucket.get_blob(f'postings_gcp{dir_name}/' + file_name)\n","    return blob.open('rb')\n","\n","def read_pickle(file_name,dir_name):\n","    stream = open_gcp(file_name+\".pickle\",dir_name)\n","    pick = pickle.load(stream)\n","    stream.close()\n","    return pick\n","\n","def read_pkl(file_name,dir_name):\n","    stream = open_gcp(file_name+\".pkl\",dir_name)\n","    pick = pickle.load(stream)\n","    stream.close()\n","    return pick"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"nxdnr1o_zMA4"},"outputs":[],"source":["sc.addFile(\"/home/dataproc/inverted_index_gcp.py\")\n","sys.path.insert(0,SparkFiles.getRootDirectory())"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"sNv3jYMBs8-r"},"outputs":[],"source":["bucket_name = '208987248' \n","client = storage.Client()\n","blobs = client.list_blobs(bucket_name)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"-Sompm9qs_fr"},"outputs":[],"source":["from inverted_index_gcp import *"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"zzN4reXLtCEe"},"outputs":[],"source":["inverted_text = read_pkl('index','')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"g6j44L7WtD9T"},"outputs":[],"source":["inverted_title = read_pkl('index_title','title')"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"T_zOM6zNtH19"},"outputs":[],"source":["DL_dict = read_pickle('text_DL','')\n","inverted_text.DL = DL_dict"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"TB144qR2tNL-"},"outputs":[],"source":["TUPLE_SIZE = 6       \n","TF_MASK = 2 ** 16 - 1 # Masking the 16 low bits of an integer\n","from contextlib import closing\n","\n","def read_posting_list(inverted, w, base_dir):\n","    with closing(MultiFileReader()) as reader:\n","        locs = inverted.posting_locs[w]\n","        b = reader.read(locs, inverted.df[w] * TUPLE_SIZE, base_dir)\n","        posting_list = []\n","        for i in range(inverted.df[w]):\n","            doc_id = int.from_bytes(b[i*TUPLE_SIZE:i*TUPLE_SIZE+4], 'big')\n","            tf = int.from_bytes(b[i*TUPLE_SIZE+4:(i+1)*TUPLE_SIZE], 'big')\n","            posting_list.append((doc_id, tf))\n","        return posting_list"]},{"cell_type":"markdown","metadata":{"id":"juqkKEsgzeUl"},"source":["## Starting Search"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"U2jcVjHI0901"},"outputs":[],"source":["def get_candidate_documents(query_to_search,index,base_dir):\n","    candidates = []    \n","    for term in np.unique(query_to_search):\n","        if term in index.df.keys():        \n","            current_list = read_posting_list(index, term,base_dir )               \n","            candidates += current_list    \n","    candidates = set([x[0] for x in candidates])\n","    return set(candidates)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Dq1cjkLMxUvD"},"outputs":[],"source":["import math\n","from itertools import chain\n","import time\n","# When preprocessing the data have a dictionary of document length for each document saved in a variable called `DL`.\n","class BM25_from_index:\n","    \"\"\"\n","    Best Match 25.    \n","    ----------\n","    k1 : float, default 1.5\n","\n","    b : float, default 0.75\n","\n","    index: inverted index\n","    \"\"\"\n","\n","    def __init__(self,index,base_dir='',k1=1.5, b=0.75):\n","        self.b = b\n","        self.k1 = k1\n","        self.index = index\n","        self.N = len(index.DL)\n","        self.AVGDL = builtins.sum(index.DL.values())/self.N\n","        self.base_dir = base_dir\n","\n","    def calc_idf(self,list_of_tokens):\n","        idf = {}        \n","        for term in list_of_tokens:            \n","            if term in self.index.df.keys():\n","                n_ti = self.index.df[term]\n","                idf[term] = math.log(1 + (self.N - n_ti + 0.5) / (n_ti + 0.5))\n","            else:\n","                pass                             \n","        return idf\n","        \n","\n","    def search(self, queries,N=100):\n","        dict_B25 = {}\n","        unique_terms_in_queries = []\n","        unique_terms_in_queries = [q for q in queries.values()]\n","        unique_terms_in_queries = [item for sublist in unique_terms_in_queries for item in sublist]\n","        unique_terms_in_queries = list(set(unique_terms_in_queries))\n","        idf = self.calc_idf(unique_terms_in_queries)\n","        self.idf = idf\n","        pls_dict = {}\n","        for q_id,q in queries.items():\n","            for term in q:\n","                if term in self.index.df.keys() and term not in pls_dict:  \n","                    pls_dict[term] = dict(read_posting_list(self.index, term ,self.base_dir))\n","            candidates = get_candidate_documents(q, self.index,self.base_dir)\n","            dict_B25[q_id] = [(c, self._score(q,c,pls_dict)) for c in candidates]\n","            dict_B25[q_id] = sorted(dict_B25[q_id] , key = lambda x: x[1], reverse = True)[:N]\n","        return dict_B25\n","\n","    def _score(self,query, doc_id, pls_dict):  \n","        score = 0.0        \n","        doc_len = self.index.DL[doc_id]        \n","        for term in query:\n","            if term in self.index.df.keys():                 \n","                if doc_id in pls_dict[term].keys():            \n","                    freq = pls_dict[term][doc_id]\n","                    numerator = self.idf[term] * freq * (self.k1 + 1)\n","                    denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.AVGDL)\n","                    score += (numerator / denominator)\n","        return score"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"U30ntvCo0P1v"},"outputs":[],"source":["bm25_text = BM25_from_index(inverted_text)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["dict_query = {}\n","bm25_queries_score_train = bm25_text.search(dict_query,100)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"d0xZcaKg0Qb4"},"outputs":[],"source":["def merge_results(title_scores,body_scores,title_weight=0.5,text_weight=0.5,N = 100):    \n","        dict_topN = {}\n","        for q_id in title_scores:\n","            tuples_title = title_scores[q_id]\n","            doc_id_title = [x[0] for x in tuples_title]\n","\n","            tuples_body = body_scores[q_id]\n","            doc_id_body = [x[0] for x in tuples_body]\n","\n","            list_diff_id = [x for x in doc_id_title if x not in doc_id_body] + [x for x in doc_id_body if x not in doc_id_title]\n","            list_same_id = [x for x in doc_id_title if x not in list_diff_id]\n","\n","            tuples_diff = [(x[0], x[1] * title_weight) for x in tuples_title if x[0] in list_diff_id] + [(x[0], x[1] * text_weight) for x in tuples_body if x[0] in list_diff_id]\n","\n","            dict_same = {}\n","            for x, y in tuples_title: \n","                if(x in list_same_id):\n","                    dict_same.setdefault(x, []).append(y)\n","            for x, y in tuples_body: \n","                if(x in list_same_id):\n","                      dict_same.setdefault(x, []).append(y)\n","            tuples_same = [(x, y[0] * title_weight + y[1] * text_weight) for x, y in dict_same.items()]\n","\n","            new_tuples = tuples_same + tuples_diff\n","            new_tuples = sorted(new_tuples, key=lambda t: t[1], reverse=True)[:N]\n","            dict_topN[q_id] = new_tuples\n","        return dict_topN"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["bm25_title = BM25_from_index(inverted_title,'title')\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["bm25_queries_score_train_title = bm25_title.search(dict_query,100)\n","bm25_queries_score_train_body = bm25_text.search(dict_query,100)\n","\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[46332325, 21356332, 18805500, 5087621, 46448252, 8005736, 57197811, 4920126, 2009536, 2032271, 639888, 13370873, 47063809, 83036, 13062829, 6146589, 3526151, 88595, 13371283, 14985517, 30796675, 4930338, 10720945, 4195298, 696712, 3673376, 23862, 24193668, 5204237, 6081823, 16274121, 54778043, 5250192, 2377926, 42369403, 13213953, 1255122, 25061839, 58429169, 24193838, 3274540, 21727049, 21965279, 1996367, 16305806, 30714017, 1984246, 3596573, 10849171, 49119569, 34292335, 31354866, 645025, 1810666, 18384111, 41170321, 3257046, 2781093, 50020765, 6823999, 390263, 44783363, 51218917, 29772882, 13205433, 890353, 40170617, 34192383, 32910103, 2564605, 2901907, 36091677, 7680006, 4225907, 56115363, 29040606, 33828979, 1270266, 6548215, 2843493, 40971733, 23329, 11322015, 59662859, 46315592, 14969781, 46233379, 2852798, 30431128, 30722935, 750633, 47640599, 47623894, 17474156, 47337433, 8471397, 23045823, 730903, 28344538, 226402]\n","100\n"]}],"source":["search_result_dic = merge_results(bm25_queries_score_train_title,bm25_queries_score_train_body,0.50,0.50)\n","search_result_lst = [x[0] for x in search_result_dic[1]]\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Big Search.ipynb","provenance":[]},"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":1}